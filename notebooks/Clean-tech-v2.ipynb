{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Technologies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_excel('../data/categories.xls')\n",
    "categories = categories.fillna(method='ffill')\n",
    "categories.columns = ['sector','technology_group','technology','description','technology_term','source']\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for term in categories['technology_term']:\n",
    "    row = [x.strip() for x in term.split(',')]\n",
    "    row = [i.replace('“', '').replace('”', '') for i in row]\n",
    "    matrix.append(row)\n",
    "categories['technology_term'] = matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.europa.eu/euodp/en/data/dataset/cordisH2020projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020 = pd.read_excel('../data/cordis-h2020projects.xlsx')\n",
    "#cordish2020 = pd.read_csv('../data/cordis-h2020projects.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020['totalCost'] = [float(str(i).replace(',', '.')) for i in cordish2020['totalCost']]\n",
    "cordish2020['ecMaxContribution'] = [float(str(i).replace(',', '.')) for i in cordish2020['ecMaxContribution']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020['startDate'] = cordish2020['startDate'].map(pd.Timestamp)\n",
    "cordish2020['endDate'] = cordish2020['endDate'].map(pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total of proyects\n",
    "len(cordish2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective example\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020.loc[13]['objective']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic text labeling, Flashtext for easy regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(vec, dictionary, info=False):\n",
    "    empty = []\n",
    "    for line in vec:\n",
    "        empty.append(dictionary.extract_keywords(line, span_info=info))\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique list of technology group\n",
    "technology_group = list(categories['technology_group'].unique())\n",
    "len(technology_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary1 = KeywordProcessor()\n",
    "dictionary1.add_keywords_from_list(technology_group)\n",
    "extracted1 = extract(cordish2020['objective'], dictionary1)\n",
    "cordish2020['matches_group'] = [list(set(i)) if len(i)>0 else '' for i in extracted1]\n",
    "cordish2020['count_matches_group'] = [len(i) for i in extracted1]\n",
    "cordish2020['count_unique_matches_group'] = [len(set(i)) for i in extracted1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique list of technology term\n",
    "technology_term = [y for x in categories['technology_term'] for y in x if y != '']\n",
    "len(technology_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the new list of terms\n",
    "dictionary2 = KeywordProcessor()\n",
    "dictionary2.add_keywords_from_list(technology_term)\n",
    "extracted2 = extract(cordish2020['objective'], dictionary2)\n",
    "cordish2020['matches_technology'] = [list(set(i)) if len(i)>0 else '' for i in extracted2]\n",
    "cordish2020['count_matches_technology'] = [len(i) for i in extracted2]\n",
    "cordish2020['count_unique_matches_technology'] = [len(set(i)) for i in extracted2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cordish2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only the rows with at least one match\n",
    "cordish2020['count_matches'] = cordish2020['count_matches_group'] + cordish2020['count_matches_technology'] \n",
    "cordish2020matches = cordish2020[cordish2020['count_matches_technology'] > 0 ] #at least one match with technology term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cordish2020matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cordish2020matches)/len(cordish2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the list we need to compare with the probabilistic\n",
    "cordish2020matches.id[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020matches.sort_values('count_matches', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one hypthesis here:  \n",
    "The more count matches you have the better the accuracy to detect technology terms in the objective text  \n",
    "Might be solved with statistical sampling. For each count match, select a sample check manually the accuracy  \n",
    "http://www.marknagelberg.com/using-python-to-figure-out-sample-sizes-for-your-study/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA\n",
    "1. Group by month and count over the time\n",
    "2. Group by month and sum the total cost over the time\n",
    "3. Group by country coordinator and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = cordish2020matches.groupby(cordish2020matches['startDate'].map(lambda x: x.year)).count()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = cordish2020matches.groupby(cordish2020matches['startDate'].map(lambda x: x.year)).sum()['ecMaxContribution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = cordish2020matches.groupby(['coordinator','coordinatorCountry']).count()['id'].sort_values(ascending=False).reset_index()\n",
    "df_c.columns = ['coordinator','coordinatorCountry','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = cordish2020matches.groupby(['coordinator','coordinatorCountry']).sum()['ecMaxContribution'].sort_values(ascending=False).reset_index()\n",
    "df_c.columns = ['coordinator','coordinatorCountry','sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms_matrix(vector_of_terms, all_terms):\n",
    "    matrix = []\n",
    "    for vector in vector_of_terms:\n",
    "        ind_vector = [0] * len(all_terms)\n",
    "        for v in vector:\n",
    "            for idx, i in enumerate(all_terms):\n",
    "                if v == i:\n",
    "                    ind_vector[idx] = 1\n",
    "        matrix.append(ind_vector)\n",
    "    table = pd.DataFrame(matrix)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_technology_terms = [i for i in set([*list(categories['technology_group']),*list(technology_term)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_technology_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_technology_terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected to have 225 columns\n",
    "matches_technology_table = get_terms_matrix(list(cordish2020matches['matches_technology']), all_technology_terms)\n",
    "matches_group_table = get_terms_matrix(list(cordish2020matches['matches_group']), all_technology_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_table = matches_group_table + matches_technology_table\n",
    "matches_table.columns = all_technology_terms\n",
    "matches_table['number_unique_terms'] = matches_table.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches_table) == len(cordish2020matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table_tech_matches = pd.concat([cordish2020matches.reset_index(), matches_table], axis=1).sort_values(['count_matches','number_unique_terms'], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_table_tech_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(full_table_tech_matches['number_unique_terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(full_table_tech_matches['count_matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table_tech_matches.groupby('count_matches').count()['number_unique_terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, j in zip(full_table_tech_matches[full_table_tech_matches['count_matches'] ==2]['matches_technology'],full_table_tech_matches[full_table_tech_matches['count_matches'] ==2]['matches_group']):\n",
    "#    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_table_tech_matches.columns[:35]#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in full_table_tech_matches.columns:\n",
    "#    print(i)\n",
    "#count_matches: each time a term in the glossary of 225 terms appear\n",
    "#number_unique_terms: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table_tech_matches[['id','acronym','title','objective','startDate','endDate','ecMaxContribution','matches_group','matches_technology','number_unique_terms','count_matches']].to_csv('../data/tech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termsT = full_table_tech_matches.iloc[:,33:-1].T\n",
    "termsT['sum'] = termsT.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#termsT.sort_values('sum', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(termsT[termsT['sum']>0])/len(termsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../data/tech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Syntactic probabilistic classification using spacy and fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import re\n",
    "nlp = en_core_web_sm.load()\n",
    "import textdistance as tx\n",
    "import unicodedata\n",
    "from textdistance.algorithms import vector_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return re.sub(r'[-\\s]+', '-',\n",
    "                str(\n",
    "                    re.sub(r'[^\\w\\s-]', '',\n",
    "                        unicodedata.normalize('NFKD', string)\n",
    "                    .strip()\n",
    "                   )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective example\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020.loc[13]['objective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cordish2020['objective'][13]\n",
    "doc = nlp(text)\n",
    "docs = list(map(str, doc.noun_chunks))\n",
    "docs[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all the synonyms from the short descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technologies = all_technology_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(technologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_matching_tech(techs, doc):\n",
    "    best_matches = []\n",
    "    best1 = [(\"\", 0)]\n",
    "    best2 = [(\"\", 0)]\n",
    "    val2=\"\"\n",
    "    best_tech = []\n",
    "    for val in techs:\n",
    "        best_curs = process.extract(val, doc, limit=1, scorer=fuzz.ratio)\n",
    "        terms = \"\"\n",
    "        for cat in best_curs:\n",
    "            terms = terms + cat[0] + \",\" \n",
    "        terms = terms[:-1]\n",
    "        if len(best_curs)==0:\n",
    "            avg = 0\n",
    "        else:\n",
    "            avg = sum(i for _, i in best_curs)/float(len(best_curs))\n",
    "        best_cur = [(terms, avg)]\n",
    "        best_matches.extend(best_cur)\n",
    "        if best_cur[0][1] > best1[0][1]:\n",
    "            best1 = best_cur\n",
    "            best_tech = [val]\n",
    "        elif best_cur[0][1] == best1[0][1]:\n",
    "            best1.extend(best_cur)\n",
    "            best_tech.append(val)\n",
    "        else:\n",
    "            if best_cur[0][1] > best2[0][1] and len(best1)<3:\n",
    "                best2 = best_cur\n",
    "                val2 = val\n",
    "    if len(best1)<3:            \n",
    "        best1.extend(best2)\n",
    "        best_tech.append(val2)\n",
    "    return best_matches, best_tech, best1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process.extract(each tech term, each noun chunk in each objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020['category'] = pd.Series(np.random.randn(len(cordish2020)), index=cordish2020.index)\n",
    "for idx in range(len(cordish2020['objective'])):\n",
    "    text = cordish2020['objective'][idx]\n",
    "    doc = nlp(text)\n",
    "   # doc = \" \".join([token.lemma_ for token in doc])\n",
    "    #doc = nlp(doc)\n",
    "    docs = list(map(str, doc.noun_chunks))\n",
    "    #docs = [clean(str(txt)) for txt in docs]\n",
    "    _, best_tech, best_match = find_best_matching_tech(technologies, docs)\n",
    "    #print(best_tech, best_match)\n",
    "    if round(best_match[0][1]) > 77:\n",
    "        cordish2020['category'][idx] = \" \".join(best_tech)\n",
    "    else:\n",
    "        cordish2020['category'][idx] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category is the column to store the best matches with technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020['category'].value_counts()['None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020matches2 = cordish2020[cordish2020['category'] != \"None\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cordish2020matches2)/len(cordish2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020matches2.id[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordish2020matches2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cordish2020['objective'][13]\n",
    "doc = nlp(text)\n",
    "#doc = \" \".join([token.lemma_ for token in doc])\n",
    "#doc = nlp(doc)\n",
    "docs = list(map(str, doc.noun_chunks))\n",
    "_, best_tech, best_match = find_best_matching_tech(technologies, docs)\n",
    "print(best_tech,best_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
